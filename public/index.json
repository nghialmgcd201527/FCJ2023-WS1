[
{
	"uri": "/2-prerequiste/2.1-createcloud9workspace/",
	"title": "Create a Cloud9 Workspace",
	"tags": [],
	"description": "",
	"content": "Create a Cloud9 Workspace Type Cloud9 in the service search bar on the AWS Console then select Cloud9. Click Create environment Name the Cloud9 Workspace serverless-workshop. In the Description field, enter the purpose you want to use in this workspace. Enter deploy \u0026ldquo;Todos app\u0026rdquo; Environment type, here we will create a server to run this Cloud9 workspace. I will choose New EC2 instance option to create a new server. Go to settings for New EC2 instance, select Additional instance types then we choose t3.medium Leave defaults for other settings. Click the Create button Wait about 10 minutes for Cloud9 Workspace to be created. Once the Cloud9 Workspace is created, we will have an environment to work with the AWS CLI and other tools. In the list of Environments created, find the serverless-workshop environment and click the Open button to open the Cloud9 environment. After the environment opens, let\u0026rsquo;s close the sections below that were initialized at the start and create a new terminal page. Our workspace will look like this.\n"
},
{
	"uri": "/3-serverlessbackend/3.1-dynamodb/",
	"title": "Define a DynamoDB table",
	"tags": [],
	"description": "",
	"content": "What is Amazon DynamoDB? Amazon DynamoDB is a serverless key-value pair and a type of non-relational (Non-SQL) database that delivers millisecond performance at all sizes.\nSimilar to other databases, Amazon DynamoDB stores data in tables. In our application, we will store the information of the tasks in the table of DynamoDB. This table will be accessed by the Lambda function in response to the API from our web application.\nWe will use SAM to initialize the DynamoDB table.\nAdd the DynamoDB table to the SAM template The line AWS:DynamoDB::Table is used to define the DynamoDB table.\nGo to the template.yaml file in the sam folder, add the following code in the Resource section and below the MyAuthFunction function.\n# Create DynamoDB table\rTasksTable:\rType: AWS::DynamoDB::Table\rProperties:\rAttributeDefinitions:\r- AttributeName: \u0026#34;user\u0026#34;\rAttributeType: \u0026#34;S\u0026#34;\r- AttributeName: \u0026#34;id\u0026#34;\rAttributeType: \u0026#34;S\u0026#34;\rKeySchema:\r- AttributeName: \u0026#34;user\u0026#34;\rKeyType: \u0026#34;HASH\u0026#34;\r- AttributeName: \u0026#34;id\u0026#34;\rKeyType: \u0026#34;RANGE\u0026#34;\rBillingMode: PAY_PER_REQUEST First you will have AttributeDefinitions where the attributes (columns) are defined in the DynamoDB table. In our table, there are 2 attributes defined as users and id. Both are of type string (AttributeType: \u0026quot;S\u0026quot;).\nKeySchema defines the primary key of the table. The primary key of the table is a combination of the two attributes user and id. user is the hash key (KeyType: \u0026quot;HASH\u0026quot;) and id is the range key (KeyType: \u0026quot;RANGE\u0026quot;). This indicates that the table will be managed, partitioned based on the user and id attributes.\nBillingMode: PAY_PER_REQUEST defines how to pay for that table as payment on demand.\nThe syntax in YAML is space sensitive, so make sure the scope of the TasksTable function is indented deeper than the scope of Resources.\nWe will have the result as shown below.\nFor more information about AWS::Serverless::Table, refer to SAM\u0026rsquo;s resource here.\n"
},
{
	"uri": "/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "The application architecture uses AWS Lambda, Amazon API Gateway, Amazon DynamoDB, Amazon Simple Storage Service (S3), and AWS Amplify Console. Amplify Console provides continuous deployment and hosting of the static web resources including HTML, CSS, JavaScript, and image files which are loaded in the user\u0026rsquo;s browser. JavaScript executed in the browser sends and receives data from a public backend API built using Lambda and API Gateway. DynamoDB provides a persistence layer where data can be stored by the API\u0026rsquo;s Lambda function. S3 is used to store uploaded images. Finally, Amazon Rekognition is used to detect and label objects in those images.\n"
},
{
	"uri": "/",
	"title": "Session Management",
	"tags": [],
	"description": "",
	"content": "Deploy \u0026ldquo;Todo app\u0026rdquo; with Serverless Overall In this workshop, we will create a “Todo app” using Serverless and API to store and retrieve data in the Cloud. In addition, we will combine Machine Learning to identify keywords related to the images that you upload for each Task.\nContent Introduction Prerequisites Build a serverless backend: AWS Lambda and AWS SAM Configure API authorization: API Gateway Build and deploy a web application: AWS Amplify Test the application Configure image metadata extraction: Amazon Rekognition Terminate Resources "
},
{
	"uri": "/3-serverlessbackend/3.2-lambdafunction/",
	"title": "Create a Lambda function",
	"tags": [],
	"description": "",
	"content": "What is AWS Lambda? AWS Lambda is a serverless compute service that lets you run code without provisioning or managing servers. Lambda automatically allocates compute power and runs your code based on the incoming request or event, for any scale of traffic.\nHow it works:\nUpload your code to AWS Lambda or write code in Lambda\u0026rsquo;s code editor. (In this workshop, we\u0026rsquo;ll be writing code and uploading it using SAM.) Set up your code to trigger from other AWS services, HTTP endpoints, or in-app activity. Lambda runs your code only when triggered, using only the compute resources needed. Just pay for the compute time you use. Anatomy of a Lambda function The Lambda function handler is the method in your function code that processes events. When your function is invoked, Lambda runs the handler method. When the handler exits or returns a response, it becomes available to handle another event.\nExample Lambda function structure:\nexports.handler = async (event) =\u0026gt; {\r// TODO implement\rconst response = {\rstatusCode: 200,\rbody: JSON.stringify(\u0026#39;Hello from Lambda!\u0026#39;),\r};\rreturn response;\r}; Here, the event is the incoming request. The response is the outgoing response.\nCreate a Lambda function Go to the path sam/src/handlers/createTask and select the file named app.js, copy and paste the following code into the file:\nconst { DynamoDBClient } = require(\u0026#39;@aws-sdk/client-dynamodb\u0026#39;)\rconst { DynamoDBDocumentClient, PutCommand } = require(\u0026#39;@aws-sdk/lib-dynamodb\u0026#39;)\rconst uuid = require(\u0026#39;uuid\u0026#39;)\rconst ddbClient = new DynamoDBClient()\rconst ddbDocClient = DynamoDBDocumentClient.from(ddbClient)\rconst tableName = process.env.TASKS_TABLE\rexports.handler = async (event) =\u0026gt; {\rconsole.info(\u0026#39;received:\u0026#39;, event)\rconst body = JSON.parse(event.body)\rconst user = event.requestContext.authorizer.principalId\rconst id = uuid.v4()\rconst title = body.title\rconst bodyText = body.body\rconst createdAt = new Date().toISOString()\rlet dueDate = createdAt\rif (\u0026#39;dueDate\u0026#39; in body) {\rdueDate = body.dueDate\r}\rconst params = {\rTableName: tableName,\rItem: { user: `user#${user}`, id: `task#${id}`, title: title, body: bodyText, dueDate: dueDate, createdAt: createdAt }\r}\rconsole.info(`Writing data to table ${tableName}`)\rconst data = await ddbDocClient.send(new PutCommand(params))\rconsole.log(\u0026#39;Success - item added or updated\u0026#39;, data)\rconst response = {\rstatusCode: 200,\rheaders: {\r\u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39;\r},\rbody: JSON.stringify(data)\r}\rreturn response\r} This code imported the AWS SDK library for DynamoDB, the uuid library for identification, and installed the DynamoDB client.\nLambda function is initialized with exports.handler, which acts as an entry point of the function. It takes an envent object as an input parameter and returns a response. object\nIt creates a params object with the necessary elements, including the name of the DynamoDB table, the properties of the item in the table (user, id, title, bodyText, dueDate, createdAt).\nThe function logs data to the DynamoDB table with PutCommand and logs a success message.\nResponse will return an object with statusCode of 200, set headers with CORS and body as the logged data.\nIn short, this code serves to create and update tasks in DynamoDB table based on sending API request. It leverages the AWS SDK for DynamoDB, Node.js, and AWS Lambda to provide a scalable and serverless task management solution.\nAdd the Lambda function to the SAM template Copy and paste the code below into the Resource section of the file template.yml, after the function TasksTable.\nThe syntax in YAML is space sensitive, so make sure the scope of the CreateTaskFunction function is indented deeper than the scope of Resources.\nThe value AWS::Serverless::Function is used to initialize the Lambda function. The CodeUri attribute is used to specify the location of the app.js file in the src/handlers/createTask directory.\n# CreateTask Lambda Function\rCreateTaskFunction:\rType: AWS::Serverless::Function\rProperties:\rCodeUri: src/handlers/createTask\rHandler: app.handler\rPolicies:\r- DynamoDBCrudPolicy:\rTableName: !Ref TasksTable\rEnvironment:\rVariables:\rTASKS_TABLE: !Ref TasksTable\rEvents:\rPostTaskFunctionApi:\rType: Api\rProperties:\rRestApiId: !Ref TasksApi\rPath: /tasks\rMethod: POST\rAuth:\rAuthorizer: MyLambdaTokenAuthorizer Details and uses of the attributes declared above can be reviewed in this.\nDo as shown below.\n"
},
{
	"uri": "/2-prerequiste/2.2-ensurenodejsversion/",
	"title": "Ensure Node.js Version",
	"tags": [],
	"description": "",
	"content": "Cloud9 has Node.js pre-installed but it may not be compatible with the time I do this workshop. To ensure this, install Node.js v16 (codename Gallium) by running the following command in the Cloud9 terminal.\nLet\u0026rsquo;s check the current Node.js version running on Cloud9 with the following command:\nnode --version This is the version of Node.js that I am using in this workshop.\nIf the version of Node.js you are using is v16.x then you can skip this step and go to Clone Git repository. If the version you are using is different from the above then follow along Follow these steps to install the right version of Node.js for this workshop using the terminal page you just created.\nAt the terminal page on Cloud9, run the following command to make sure you have the latest version of Node.js Version Manager (nvm) installed (At the time I wrote the workshop, it was version 0.39.0).\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.2/install.sh | bash Next we will install Node.js v16 \u0026ldquo;Gallium\u0026rdquo;:\nnvm install \u0026#39;lts/gallium\u0026#39; Finally, we will choose the above Node.js version as the default version:\nnvm alias default \u0026#39;lts/gallium\u0026#39; Review the Node.js instance running on Cloud9 with the following command:\nnode --version The result we need is to start with v16.\n"
},
{
	"uri": "/2-prerequiste/",
	"title": "Prerequisite",
	"tags": [],
	"description": "",
	"content": "\rRemember that Cloud9 workspaces should only be created by an IAM user (or assigned to an appropriate IAM role) with Admin privileges, not a root user.\nCloud9 Workspace We often use the Integrated Development Environment (IDE) locally, in this workshop we will use Cloud9. It is an IDE that runs in the cloud using a browser, including the important, essential features in the local IDE that we often use such as writing, running, debugging code. Cloud9 already comes with bundles of files like JavaScript, Python, NodeJS and others here\nFor AWS services\u0026rsquo; faster response, we recommend you to select the nearest Region during this workshop.\nRegion Support for Amazon Rekognition Note that not all services are available in all regions. Later in this workshop, we will be using Amazon Rekognition, which is available only in the following regions::\nUS East (Ohio) us-east-2 US East (N. Virginia) us-east-1 US West (N. California) us-west-1 US West (Oregon) us-west-2 Asia Pacific (Mumbai) ap-south-1 Asia Pacific (Seoul) ap-northeast-2 Asia Pacific (Singapore) ap-southeast-1 Asia Pacific (Sydney) ap-southeast-2 Asia Pacific (Tokyo) ap-northeast-1 Canada (Central) ca-central-1 Europe (Frankfurt) eu-central-1 Europe (Ireland) eu-west-1 Europe (London) eu-west-2 See more Amazon Rekognition latest updates.\nContent Create a Cloud9 Workspace Ensure Node.js Version Clone the Git repository and avoid free space issues with Cloud9 Install Amplify CLI "
},
{
	"uri": "/3-serverlessbackend/",
	"title": "Build a serverless backend: AWS Lambda and AWS SAM",
	"tags": [],
	"description": "",
	"content": "Overview In this section, we will use the Serverless Application Model (SAM) to build a backend process to handle requests from the web application. The application that we are going to deploy here allows users to create todo tasks and assign files to those tasks. To meet those requirements, JavaScript running in the browser needs to rely on a service in the cloud.\nYou will use a Lambda function so that every time a user creates a task, it will be called to execute. This function will store the task to DynamoDB, then will send the response to the front-end and update the new task on the front-end.\nThe function is called from the browser using Amazon API Gateway. You will implement this connection later. In this section, you will only test your function in isolation.\nWhat is SAM? Serverless Application Model (SAM) is an open-source framework that will make serverless application deployment easier. It provides a simple way to define serverless applications, and provides a set of tools for deploying those applications.\nIt allows us to specify the requirements of the application in code. SAM transforms and extends the SAM syntax to AWS Cloudformation to deploy your applications. You will see and use SAM templates throughout this workshop.\nHow does SAM work? AWS SAM is based on AWS Cloudformation. A serverless application is defined with a CloudFormation template and deployed with the CloudFormation stack. In short, the AWS SAM template is a CloudFormation template.\nAWS SAM defines a set of resources that describe common components of a serverless application. In order for AWS SAM to have objects defined in the CloudFormation template, the template must include a Transform section in the document root of AWS::Serverless-2016-10-31.\nOur sample application: Tasks API The API Tasks that we will build in this workshop include Amazon API Gateway HTTP endpoints to trigger AWS Lambda functions, which will read and write data to the Amazon DynamoDB database. The SAM template of the Tasks API will include a DynamoDB table, Lambda functions to list, view, and update Tasks in the table.\nIn this section, you will work with a Lambda function to create a new task. Tasks API components are defined in template.yaml. Next we will go into detail about the structure of the Lambda function.\nAnatomy of SAM template Go to the serverless-tasks-web folder followed by the sam folder then open the template.yaml file. Below is a piece of code in the SAM template file that lists the tasks:\nThese are the properties defined in the resource AWS:Serverless:Function, we will start to learn about them.\nFunctionName\nThe FunctionName property is optionally named for the Lambda function. If we don\u0026rsquo;t name it, CloudFormation will use the name of CloudFormation Stack, CloudFormation Resource and random ID.\nCodeUri\nThe CodeUri attribute specifies the path to the source code of the Lambda function in the workspace associated with the SAM template in the sam/ path. In this example, the Code snippet will be in the path src/handlers/ and getTasks will be its function.\nHandler\nThe Handler attribute specifies the entry point for the Lambda function. For Javascript, it will be formatted as file.function, where file is the filename containing the function without the extension .js belonging to the path CodeUri defined above and function is the name of the function in that file that will be executed when the Lambda function is called.\nEnvironment\nThe Environment attribute defines an environment variable, which will be available in the Lambda function. In this example, we are defining an environment variable TASKS_TABLE with a value of TasksTable. This environment variable will be used in the Lambda function to access the DynamoDB table where the tasks are stored.\nEvents\nThe Events attribute defines the events that will trigger the Lambda function when called. Event API is integrated with Lambda function and API Gateway endpoint, however SAM only supports Lambda function triggers from the following sources .\nThe event API is used to view the details of a Task defined in the RESTful resource /tasks and accessed using the HTTP GET method. SAM will convert API event to API Gateways to call Lambda function.\nContent Define a DynamoDB table Create a Lambda function "
},
{
	"uri": "/2-prerequiste/2.3-clonerepositoryandavoidingfreespace/",
	"title": "Clone the Git repository and avoid free space issues with Cloud9",
	"tags": [],
	"description": "",
	"content": "At the terminal page on Cloud9, run the following command to clone the Git repository serverless-tasks-webapp:\ngit clone https://github.com/aws-samples/serverless-tasks-webapp After running the above command, we will get as shown. We should see the serverless-tasks-webapp folder created.\nAvoid Cloud9 Free Space Issues By default, the free space of a Cloud9 instance is only about 2GB. Use the script below to avoid running out of space and problems during the workshop.\nFirst, we will update to the latest version of the AWS CLI:\npip install --user --upgrade awscli aws-sam-cli If the update is successful, we will see as shown below:\nGo to the serverless-tasks-webapp directory, check the size of the current volume with the following command:\ncd serverless-tasks-webapp\rdf -h We will get the result as shown below:\nfilesystem at the path /dev/nvme0n1p1 is the volume we are using. We will see that the free space of this volume is 3.5G. To avoid running out of space during the workshop, we will increase the capacity of this volume to 20G.\nIncrease Amazon EBS volume size to 20G:\nbash resize.sh 20 We will see output like this:\ndf -h Now check the size of the current volume with the following command:\nAs we can see in the path /dev/nvme0n1p1, the free space of the current volume has increased to 14G.\n"
},
{
	"uri": "/4-apigateway/",
	"title": "Configure API authorization: API Gateway",
	"tags": [],
	"description": "",
	"content": "What is Lambda Authorizer? A Lambda authorizer is an API Gateway feature that uses a Lambda function to control access to your API. It is a way to add additional security to your API.\nHow does a Lambda Authorizer work? When a client makes a request to one of your API\u0026rsquo;s methods, API Gateway calls your Lambda authorizer, which takes the caller\u0026rsquo;s identity as input and returns an IAM policy as output.\nAPI Gateway supports open standards for authentication strategies such as OAuth and SAML.\nTypically, an identity provider is used to authenticate the caller. The identity provider is responsible for verifying the caller\u0026rsquo;s identity and returning the caller\u0026rsquo;s identity. The caller\u0026rsquo;s identity is then passed to the Lambda authorizer, which is responsible for controlling access to your API.\nIn this workshop, we won\u0026rsquo;t be implementing the the identity provider needed to vend security tokens, so we will instead be mocking the identity provider. More on this later.\nJSON Web Token (JWT) The caller\u0026rsquo;s identity is represented by a JSON Web Token (JWT). A JWT is a compact, self-contained, signed JSON object. The JWT is typically used to represent an authenticated user\u0026rsquo;s identity.\nExample JWT A JWT token consists of three parts: a header, a payload, and a signature. The header and payload are JSON objects. The signature is a digital signature that is used to verify the header and payload.\nHeader: The type (typ) of token is JWT. The algorithm (alg) is HS256, which is HMAC with SHA-256.\n{\r\u0026#34;typ\u0026#34;: \u0026#34;JWT\u0026#34;,\r\u0026#34;alg\u0026#34;: \u0026#34;HS256\u0026#34;\r} Payload: The iss attribute stores the identity provider\u0026rsquo;s name. the sub attribute stores the caller\u0026rsquo;s identity. The scope attribute stores the caller\u0026rsquo;s permissions. The jti attribute is a unique identifier for the JWT. The iat attribute stores the time at which the JWT was issued. The exp attribute stores the time at which the JWT expires.\n{\r\u0026#34;iss\u0026#34;: \u0026#34;getting-started-with-serverless\u0026#34;,\r\u0026#34;sub\u0026#34;: \u0026#34;minhnghia\u0026#34;,\r\u0026#34;scope\u0026#34;: \u0026#34;admins\u0026#34;,\r\u0026#34;jti\u0026#34;: \u0026#34;02343566e-8ff3-4a2d-ac18-c4d28ed96881\u0026#34;,\r\u0026#34;iat\u0026#34;: 1633433217,\r\u0026#34;exp\u0026#34;: 4070208800\r} Signature: R2D2RfY_n7OAcuONbpPfxqBY5IppEiGLCCfeQ_wz_2w Các giá trị này đều được mã hóa dạng base64 và nối với form của JWT bằng dấu \u0026ldquo;.\u0026rdquo;, ví dụ như sau:\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJsb2dnZWRJbkFzIjoiYWRtaW4iLCJpYXQiOjE0MjI3Nzk2Mzh9.gzSraSYS8EXBxLN_oWnFSRgCzcmJmMjLiuyu5CSpyHI You will see this token passed by the web application to the API Gateway endpoint using an HTTP Authorization header.\nConfigure a Lambda Authorizer Copy the code below and paste it into the app.js file in the sam/src/auth directory.\nconst jwt = require(\u0026#39;njwt\u0026#39;)\rexports.handler = function (event, context, callback) {\rconsole.info(\u0026#39;received:\u0026#39;, event)\rconst token = event.authorizationToken.split(\u0026#39; \u0026#39;)[1]\rjwt.verify(token, \u0026#39;secretphrase\u0026#39;, (err, verifiedJwt) =\u0026gt; {\rif (err) {\rconsole.log(err.message)\rcallback(\u0026#39;Error: Invalid token\u0026#39;)\r} else {\rconsole.log(`Verified token: ${verifiedJwt}`)\rconst resource = `${event.methodArn.split(\u0026#39;/\u0026#39;, 2).join(\u0026#39;/\u0026#39;)}/*`\rconst policy = generatePolicy(verifiedJwt.body.sub, \u0026#39;Allow\u0026#39;, resource)\rconsole.log(`Generated policy: ${JSON.stringify(policy)}`)\rcallback(null, policy)\r}\r})\r}\rconst generatePolicy = function (principalId, effect, resource) {\rconst authResponse = {}\rauthResponse.principalId = principalId\rif (effect \u0026amp;\u0026amp; resource) {\rconst policyDocument = {}\rpolicyDocument.Version = \u0026#39;2012-10-17\u0026#39;\rpolicyDocument.Statement = []\rconst statementOne = {}\rstatementOne.Action = \u0026#39;execute-api:Invoke\u0026#39;\rstatementOne.Effect = effect\rstatementOne.Resource = resource\rpolicyDocument.Statement[0] = statementOne\rauthResponse.policyDocument = policyDocument\r}\rauthResponse.context = {\ruserId: 1,\rcreatedAt: new Date().toISOString()\r}\rreturn authResponse\r} The code above will verify and authenticate the requests sent to the API using JSON Web Token (JWT) and return an IAM policy for that authenticated person.\nStarting off, we\u0026rsquo;ll import the njwt library, which is used for JWT authentication.\nexports.handler is the entry point of the Lambda function. It will accept an event, a context and a callback. Event contains information about the request sent to the API. Context contains information about the Lambda function. The callback will be called when the Lambda function completes.\nThe JWT token is extracted from the authorizationToken in the request header. There will be a split method used to remove the Bearer prefix and retrieve the actual token.\nThe jwt.verify function is used to verify the token using secretphrase. If the token is invalid, the Lambda function will return an error. If the token is valid, the authenticated JWT object is retrieved and disposed of.\nThe resource variable is set to represent the resources requested from the API request.\nThe generatePolicy function is used to generate an IAM policy. It will take the value of sub (subject) from the body of the JWT, convert effect to Allow and use the resource variable to clarify that policy.\nIn summary, the code above is a simple token-based authentication method, it is used to describe how to use the token to authenticate the request. The token is passed using the header of Authorization. Then we will verify the token using (secretphrase). It\u0026rsquo;s a very common passphrase, applied in web application. We are simply mock identity provider. In practice, we will use a reputable identity provider, such as Amazon Cognito, to verify the user\u0026rsquo;s identity.\nIAM Policy Document This is an example IAM policy document that is returned to the caller. Here, principal minhnghia is granted access to the API Gateway method.\n{\r\u0026#34;principalId\u0026#34;: \u0026#34;minhnghia\u0026#34;,\r\u0026#34;policyDocument\u0026#34;: {\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Action\u0026#34;: \u0026#34;execute-api:Invoke\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:execute-api:us-east-1:0123456789012:dn3fidb5ng0/v1/*\u0026#34;\r}\r]\r},\r\u0026#34;context\u0026#34;: {\r\u0026#34;userId\u0026#34;: 1,\r\u0026#34;createdAt\u0026#34;: \u0026#34;2021-10-01T19:53:34.594Z\u0026#34;\r}\r} principalId represents the indentify of the user assigned with the request. In this code, it is assigned the value minhnghia, this IAM policy is assigned to this user with the same identifier as minhnghia.\nobject policyDocument defines the permissions assigned in the policy. Version is the version of the currently used policy language 2012-10-17. Statement is an array of permissions assigned to the user. In this code, it has only one permission, execute-api:Invoke. Effect is either Allow or Deny. Resource is a unique identifier for a particular resource. In this code, it is an identifier for an API Gateway endpoint.\ncontext is an object containing additional information about the user. It can be used to pass additional information about the user to the Lambda function. In this code, it contains two pieces of information, userId and createdAt. This is beneficial in debugging and checking the requests of that user.\n"
},
{
	"uri": "/2-prerequiste/2.4-installamplifycli/",
	"title": "Install Amplify CLI",
	"tags": [],
	"description": "",
	"content": "According to AWS, Amplify is a service designed to help developers build web and mobile applications faster. Amplify provides a set of tools and services for building web and mobile applications. Amplify CLI is part of the Amplify Framework, which provides commands to create and manage AWS resources such as Amazon Cognito, Amazon API Gateway, Amazon Lambda function, Amazon DynamoDB table, and Amazon S3 bucket.\nIn this workshop, we will only configure AWS Amplify Hosting, which provides an easily manageable service for deploying applications global static web application. It will use Amazon S3 and Amazon CloudFornt to store and deliver the static resources of that application.\nInstall the latest version of Amplify CLI by running the following command: npm i -g @aws-amplify/cli Complete the installation of Amplify CLI.\nOnce the download is complete, configure the Amplify CLI: amplify configure We will get a link https://console.aws.amazon.com/ to login to the AWS console.\nAfter logging in, press Enter and select Region that you are doing the workshop, my name is ap-southeast-1. Then press Enter to continue, we we will get a path https://console.aws.amazon.com/iamv2/home#/users/create to create a new IAM user.\nAccess the above link, name amplify-user for that user, select Next.\nBy default, we will assign AdministratorAccess permission to the user configured for Amplify CLI\nIn the Permmissions options section, select Attach policies directly. Find and select AdministratorAccess. Then click Next. On the Review and create page, select Create user.\nNext, select the newly created user amplify-user, select the Security credentials tab, under Access keys, click on Create access key.\nIn step Access key best practices \u0026amp; alternatives, select Command Line Interface (CLI) and tick Confirm then select Next.\nOn the page Set description tag, enter a description for Access key depending on your preference, leave the default and select Create access key. So you have successfully created ** Access key** for user amplify-user, save Access key and Secret access key. Go back to terminal in Cloud9, press Enter, it will ask you enter Access key and Secret access key just created. After entering, press Enter, in Profile name, I will leave default, press Enter, so I have successfully configured Amplify CLI.\nNow we are ready to use Amplify!\n"
},
{
	"uri": "/7-rekognition/",
	"title": "Manage session logs",
	"tags": [],
	"description": "",
	"content": "With Session Manager, we can view the history of connections to instances through Session history. However, we have not seen the details of the commands used in a session.\nIn this section, we will proceed to create an S3 bucket and configure the session logs feature to see the details of the commands used in the session.\nContent: Update IAM Role Create S3 Bucket Create S3 Gateway endpoint Configure Session logs "
},
{
	"uri": "/8-terminate/",
	"title": "Manage session logs",
	"tags": [],
	"description": "",
	"content": "With Session Manager, we can view the history of connections to instances through Session history. However, we have not seen the details of the commands used in a session.\nIn this section, we will proceed to create an S3 bucket and configure the session logs feature to see the details of the commands used in the session.\nContent: Update IAM Role Create S3 Bucket Create S3 Gateway endpoint Configure Session logs "
},
{
	"uri": "/5-deploy/",
	"title": "Build and deploy a web application: AWS Amplify",
	"tags": [],
	"description": "",
	"content": "\rPort Forwarding is a useful way to redirect network traffic from one IP address - Port to another IP address - Port. With Port Forwarding we can access an EC2 instance located in the private subnet from our workstation.\nWe will configure Port Forwarding for the RDP connection between our machine and Private Windows Instance located in the private subnet we created for this exercise.\nCreate IAM user with permission to connect SSM Go to IAM service management console Click Users , then click Add users. At the Add user page. In the User name field, enter Portfwd. Click on Access key - Programmatic access. Click Next: Permissions. Click Attach existing policies directly.\nIn the search box, enter ssm. Click on AmazonSSMFullAccess. Click Next: Tags, click Next: Reviews. Click Create user. Save Access key ID and Secret access key information to perform AWS CLI configuration.\nInstall and Configure AWS CLI and Session Manager Plugin To perform this hands-on, make sure your workstation has AWS CLI and Session Manager Plugin installed -manager-working-with-install-plugin.html)\nMore hands-on tutorials on installing and configuring the AWS CLI can be found here.\nWith Windows, when extracting the Session Manager Plugin installation folder, run the install.bat file with Administrator permission to perform the installation.\nImplement Portforwarding Run the command below in Command Prompt on your machine to configure Port Forwarding. aws ssm start-session --target (your ID windows instance) --document-name AWS-StartPortForwardingSession --parameters portNumber=\u0026#34;3389\u0026#34;,localPortNumber=\u0026#34;9999\u0026#34; --region (your region) Windows Private Instance Instance ID information can be found when you view the EC2 Windows Private Instance server details.\nExample command: C:\\Windows\\system32\u0026gt;aws ssm start-session --target i-06343d7377486760c --document-name AWS-StartPortForwardingSession --parameters portNumber=\u0026#34;3389\u0026#34;,localPortNumber=\u0026#34;9999\u0026#34; --region ap-southeast-1 If your command gives an error like below: SessionManagerPlugin is not found. Please refer to SessionManager Documentation here: http://docs.aws.amazon.com/console/systems-manager/session-manager-plugin-not-found\nProve that you have not successfully installed the Session Manager Plugin. You may need to relaunch Command Prompt after installing Session Manager Plugin.\nConnect to the Private Windows Instance you created using the Remote Desktop tool on your workstation. In the Computer section: enter localhost:9999. Return to the administration interface of the System Manager - Session Manager service. Click tab Session history. We will see session logs with Document name AWS-StartPortForwardingSession. Congratulations on completing the lab on how to use Session Manager to connect and store session logs in S3 bucket. Remember to perform resource cleanup to avoid unintended costs.\n"
},
{
	"uri": "/6-test/",
	"title": "Port Forwarding",
	"tags": [],
	"description": "",
	"content": "\rPort Forwarding is a useful way to redirect network traffic from one IP address - Port to another IP address - Port. With Port Forwarding we can access an EC2 instance located in the private subnet from our workstation.\nWe will configure Port Forwarding for the RDP connection between our machine and Private Windows Instance located in the private subnet we created for this exercise.\nCreate IAM user with permission to connect SSM Go to IAM service management console Click Users , then click Add users. At the Add user page. In the User name field, enter Portfwd. Click on Access key - Programmatic access. Click Next: Permissions. Click Attach existing policies directly.\nIn the search box, enter ssm. Click on AmazonSSMFullAccess. Click Next: Tags, click Next: Reviews. Click Create user. Save Access key ID and Secret access key information to perform AWS CLI configuration.\nInstall and Configure AWS CLI and Session Manager Plugin To perform this hands-on, make sure your workstation has AWS CLI and Session Manager Plugin installed -manager-working-with-install-plugin.html)\nMore hands-on tutorials on installing and configuring the AWS CLI can be found here.\nWith Windows, when extracting the Session Manager Plugin installation folder, run the install.bat file with Administrator permission to perform the installation.\nImplement Portforwarding Run the command below in Command Prompt on your machine to configure Port Forwarding. aws ssm start-session --target (your ID windows instance) --document-name AWS-StartPortForwardingSession --parameters portNumber=\u0026#34;3389\u0026#34;,localPortNumber=\u0026#34;9999\u0026#34; --region (your region) Windows Private Instance Instance ID information can be found when you view the EC2 Windows Private Instance server details.\nExample command: C:\\Windows\\system32\u0026gt;aws ssm start-session --target i-06343d7377486760c --document-name AWS-StartPortForwardingSession --parameters portNumber=\u0026#34;3389\u0026#34;,localPortNumber=\u0026#34;9999\u0026#34; --region ap-southeast-1 If your command gives an error like below: SessionManagerPlugin is not found. Please refer to SessionManager Documentation here: http://docs.aws.amazon.com/console/systems-manager/session-manager-plugin-not-found\nProve that you have not successfully installed the Session Manager Plugin. You may need to relaunch Command Prompt after installing Session Manager Plugin.\nConnect to the Private Windows Instance you created using the Remote Desktop tool on your workstation. In the Computer section: enter localhost:9999. Return to the administration interface of the System Manager - Session Manager service. Click tab Session history. We will see session logs with Document name AWS-StartPortForwardingSession. Congratulations on completing the lab on how to use Session Manager to connect and store session logs in S3 bucket. Remember to perform resource cleanup to avoid unintended costs.\n"
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]